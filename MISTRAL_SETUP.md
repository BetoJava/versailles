# Configuration Mistral AI pour le Chat
## ğŸ¯ FonctionnalitÃ©s ImplÃ©mentÃ©es

### âœ… Chat avec Streaming
- RÃ©ponses en temps rÃ©el via Server-Sent Events
- Utilisation de `mistral-large-latest` par dÃ©faut
- Gestion d'erreurs robuste

### âœ… Support des Images
- Upload d'images via l'interface
- Les images sont dÃ©crites dans le prompt
- Support de multiples formats d'images

### âœ… Historique des Conversations
- Maintien du contexte entre les messages
- Envoi de l'historique complet Ã  Mistral AI

## ğŸ”§ Structure Technique

### API Routes
- `/api/chat` : Endpoint de streaming avec Mistral AI

### tRPC Procedures
- `chatbot.prepareMessage` : Validation des donnÃ©es
- `chatbot.getResponse` : RÃ©ponses simples (pour tests)

### Composants React
- `ChatProvider` : Contexte global avec historique
- `ChatContainer` : Interface principale
- `MessageBubble` : Rendu des messages avec markdown

## ğŸ§ª Test du SystÃ¨me

1. **DÃ©marrer le serveur** :
```bash
pnpm dev
```

2. **Naviguer vers** : `http://localhost:3000/chat`

3. **Tester** :
   - Messages texte simples
   - Upload d'images
   - Streaming en temps rÃ©el
   - Suggestions prÃ©dÃ©finies

## âš™ï¸ Configuration AvancÃ©e

### Changer de ModÃ¨le
Modifiez dans `src/app/api/chat/route.ts` :
```typescript
const mistralStream = await mistral.chat.stream({
  model: "mistral-medium-latest", // ou "mistral-small-latest"
  // ...
});
```

### Ajuster les ParamÃ¨tres
```typescript
const mistralStream = await mistral.chat.stream({
  model: "mistral-large-latest",
  maxTokens: 2000,        // Plus de tokens
  temperature: 0.5,       // Moins crÃ©atif
  // ...
});
```

## ğŸ” DÃ©pannage

### Erreur "MISTRAL_API_KEY n'est pas configurÃ©e"
- VÃ©rifiez que `.env.local` existe
- VÃ©rifiez que la variable est bien nommÃ©e `MISTRAL_API_KEY`
- RedÃ©marrez le serveur aprÃ¨s modification

### Erreur de streaming
- VÃ©rifiez votre clÃ© API sur le dashboard Mistral
- VÃ©rifiez votre quota et limites de taux
- Consultez les logs du serveur pour plus de dÃ©tails

### Images non analysÃ©es
- Mistral AI ne supporte pas encore nativement la vision
- Les images sont actuellement dÃ©crites par leur nom de fichier
- Pour une vraie analyse d'images, intÃ©grez un service de vision

## ğŸ“ Notes Importantes

- **CoÃ»t** : Chaque message utilise des tokens, surveillez votre usage
- **Limites** : Respectez les limites de taux de Mistral AI
- **SÃ©curitÃ©** : Ne jamais exposer votre clÃ© API cÃ´tÃ© client
- **Performance** : Le streaming amÃ©liore l'expÃ©rience utilisateur

## ğŸ”„ Mise Ã  Jour

Pour passer Ã  d'autres LLMs :
1. Remplacez le SDK dans `/api/chat/route.ts`
2. Adaptez le format des messages
3. Modifiez les paramÃ¨tres selon le modÃ¨le
